settings:
  src_path: data/lorem_ipsum_sft.jsonl
  dst_path: data/lorem_ipsum_sft_converted.jsonl
  conversations_key: 'conversations'

instruction_data_transformation:
  role_mapping:
    human_1: User1
    human_2: User2
    gpt: Assistant

# Note: the b_assistant_token, e_assistant_token and eod_token is required to be part of the chat tempalte for proper loss masking!
# Note: conversation is data-driven by the input JSONL file under ${settings.src_path}
# Note: "\" is needed by yaml to not add whitespaces!
chat_template: |
  {{ chat_template_data['system_instruction'] + '\n' }}
  {% for turn in conversation %}
  {{ turn['from'] + ': ' }}
  {% if turn['from'] == chat_template_data['assistant_role'] %}
  {{ chat_template_data['special_tokens']['b_assistant_token'] }}
  {% endif %}
  {{ turn['value'] + '\n'}}
  {% if turn['from'] == chat_template_data['assistant_role'] %}
  {{ chat_template_data['special_tokens']['e_assistant_token'] }}
  {% endif %}
  {% endfor %}
  {{ chat_template_data['special_tokens']['eod_token'] }}

chat_template_data:
  assistant_role: Assistant
  system_instruction: "You are Mody, a helpful assistant trained by the modalities team. Answer friendly and informatively to the user's messages."
  special_tokens:
      b_assistant_token: <i>
      e_assistant_token: </i>
      eod_token: <|endoftext|>


