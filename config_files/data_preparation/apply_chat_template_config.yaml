settings:
  src_path: /raid/s3/opengptx/alignment_data/data/honey/data/en/ultrachat_200k_fastchat.jsonl
  dst_path: /raid/s3/opengptx/alignment_data/data/honey/data/en/ultrachat_200k_fastchat_converted.jsonl
  conversations_key: conversations
  pbin_creation_config_file_path: config_files/data_preparation/packed_dataset_config_lora_smol.yaml
  split_config:
    splitting:
      train: 96
      val: 2
      test: 2
    seed: 42

instruction_data_transformation:
  role_mapping:
    human: User
    gpt: Assistant

# The b_include_to_loss_token, e_include_to_loss_token are required to be part of each chat template for proper loss masking!
jinja2_chat_template: |
    {{ chat_template_data.system_instruction + '\n' }}
    {% for turn in conversation %}
    {{ turn.from + ':' }}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.b_include_to_loss_token}}
    {% else %}
    {{ " " }}
    {% endif %}
    {{ turn.value + '\n'}}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.e_assistant_token}}
    {{ chat_template_data.special_tokens.e_include_to_loss_token}}
    {% endif %}
    {% endfor %}

# The key-value pairs of chat_template_data are passed to the Jinja2 template and
# are not type checked for full compliance with the chat tempalate!
chat_template_data:
  assistant_role: Assistant
  system_instruction: "You are Mody, a helpful assistant trained by the modalities team. Answer friendly and informatively to the user's messages."
  special_tokens:
      b_include_to_loss_token: <|im_start|>
      e_include_to_loss_token: <|im_end|>
      e_assistant_token: <|end_assistant|>
