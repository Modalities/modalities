settings:
  src_path: data/lorem_ipsum_sft.jsonl
  dst_path: data/lorem_ipsum_sft_converted.jsonl
  conversations_key: 'conversations'
  chat_template_key: null

instruction_data_transformation:
  role_mapping:
    human_1: User1
    human_2: User2
    gpt: Assistant

# The b_include_to_loss_token, e_include_to_loss_token and eod_token are required to be part of each chat template for proper loss masking!
jinja2_chat_templates: 
  default: |
    {{ chat_template_data.system_instruction + '\n' }}
    {% for turn in conversation %}
    {{ turn.from + ':' }}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.b_include_to_loss_token}}
    {% else %}
    {{ " " }}
    {% endif %}
    {{ turn.value + '\n'}}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.e_include_to_loss_token}}
    {{ chat_template_data.special_tokens.e_assistant_token}}
    {% endif %}
    {% endfor %}
    {{ chat_template_data.special_tokens.eod_token }}

# The key-value pairs of chat_template_data are passed to the Jinja2 template and 
# are not type checked for full compliance with the chat tempalate!
chat_template_data:
  assistant_role: Assistant
  system_instruction: "You are Mody, a helpful assistant trained by the modalities team. Answer friendly and informatively to the user's messages."
  special_tokens:
      b_include_to_loss_token: ^
      e_include_to_loss_token: $
      e_assistant_token: Â°
      eod_token: <|endoftext|>
