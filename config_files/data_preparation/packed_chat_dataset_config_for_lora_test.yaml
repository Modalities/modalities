settings:
  src_path: /raid/s3/opengptx/alignment_data/data/honey/data/en/ultrachat_200k_fastchat_converted.44a6969.jsonl
  index_path: data/lorem_ipsum_sft_converted.44a6969.idx
  dst_path: data/lorem_ipsum_sft_converted.44a6969.pbin
  jq_pattern: .chat
  num_cpus: 1
  eod_token: <|endoftext|>
  processing_batch_size: 5
  raw_samples_queue_size: 300
  processed_samples_queue_size: 300
  sequence_length: 2048

tokenizer:
  component_key: tokenizer
  variant_key: pretrained_hf_tokenizer
  config:
    pretrained_model_name_or_path: /raid/s3/opengptx/alexj/llm_gym/models/SmolLM-1.7B/
    padding: max_length
    truncation: true
    max_length: ${settings.sequence_length}
    special_tokens:
      pad_token: ${settings.eod_token}
