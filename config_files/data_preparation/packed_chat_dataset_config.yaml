settings:
  src_path: data/lorem_ipsum_sft_converted.jsonl
  dst_path: data/lorem_ipsum_sft_converted.pbin
  index_path: data/lorem_ipsum_sft_converted.idx
  jq_pattern: .chat
  num_cpus: 1
  eod_token: <|endoftext|>
  processing_batch_size: 5
  raw_samples_queue_size: 300
  processed_samples_queue_size: 300
  sequence_length: 2048

tokenizer:
  component_key: tokenizer
  variant_key: pretrained_hf_tokenizer
  config:
    pretrained_model_name_or_path: data/tokenizer/hf_gpt2
    padding: max_length
    truncation: true
    max_length: ${settings.sequence_length}
    special_tokens:
      pad_token: <|endoftext|> # eos token
