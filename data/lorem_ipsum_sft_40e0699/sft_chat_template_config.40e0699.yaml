settings:
  src_path: data/lorem_ipsum_sft.jsonl
  dst_path: data/lorem_ipsum_sft_converted.jsonl
  conversations_key: conversations

instruction_data_transformation:
  role_mapping:
    human_1: User1
    human_2: User2
    gpt: Assistant

# The b_include_to_loss_token, e_include_to_loss_token are required to be part of each chat template for proper loss masking!
jinja2_chat_template: |
    {{ chat_template_data.system_instruction + '\n' }}
    {% for turn in conversation %}
    {{ turn.from + ':' }}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.b_include_to_loss_token}}
    {% else %}
    {{ " " }}
    {% endif %}
    {{ turn.value + '\n'}}
    {% if turn.from == chat_template_data.assistant_role %}
    {{ chat_template_data.special_tokens.e_assistant_token}}
    {{ chat_template_data.special_tokens.e_include_to_loss_token}}
    {% endif %}
    {% endfor %}

# The key-value pairs of chat_template_data are passed to the Jinja2 template and 
# are not type checked for full compliance with the chat tempalate!
chat_template_data:
  assistant_role: Assistant
  system_instruction: "You are Mody, a helpful assistant trained by the modalities team. Answer friendly and informatively to the user's messages."
  # Currently only works with HF tokenizers, as the special tokens are added to the tokenizer
  special_tokens:
      # tokens to indicate the beginning and end of the assistant's response, only needed for proper loss masking
      b_include_to_loss_token: ^
      e_include_to_loss_token: $
      # the user must need to know that any special tokens must be re-introduced in the pbin file creation config and the training config
      # if not the training will run, but the e_assistant_token might not be learned correctly, as it is per default not a special token in the tokenizer
      # the e_assistant_token is used to mask the end of the assistant's response. It will be trained and can be used as early stopping criterion during generation in inference mode
      e_assistant_token: Â°
