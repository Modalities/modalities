model: 
  component_key: model
  variant_key: model_initialized
  config:
    model:
      instance_key: model_raw
      pass_type: BY_REFERENCE
    model_initializer:
      component_key: model_initialization
      variant_key: composed
      config:
        model_type: coca
        weight_init_type: WILL_BE_REPLACED
        mean: 0.0
        std: WILL_BE_REPLACED

model_raw:
  component_key: model
  variant_key: coca
  config:
    prediction_key: logits
    audio_embd_prediction_key: audio_embeddings
    image_embd_prediction_key: image_embeddings
    video_embd_prediction_key: video_embeddings
    text_embd_prediction_key: text_embeddings
    image_cls_prediction_key: image_cls
    image_text_cls_prediction_key: image_text_cls
    audio_cls_prediction_key: audio_cls
    audio_text_cls_prediction_key: audio_text_cls
    video_cls_prediction_key: video_cls
    video_text_cls_prediction_key: video_text_cls
    text_cls_prediction_key: text_cls
    modality_keys:
      - audio
      - images
      - video
    is_audio_video: false
    individual_datasets: true
    logit_scale_prediction_key: logit_scale
    audio_encoder_config:
      sample_key: audio
      prediction_key: audio_embeddings
      block_size: 500
      n_mels: 128
      n_embd: 768
      n_heads: 4
      n_conformer_blocks: 3
      attention_config:
        attention_engine_type: default_attention
      pointwise_conv_kernel_size: 1
      depthwise_conv_kernel_size: 31
    image_encoder_config:
      sample_key: images
      prediction_key: image_embeddings
      img_size: 224
      n_classes: Null # Disable vision transformer head
      n_layer: 6
      attention_config:
        attention_engine_type: default_attention
      n_head: 8
      n_embd: 768
      dropout: 0.0
      patch_size: 16
      patch_stride: 16
      n_img_channels: 3
      add_cls_token: False
      bias: True
    video_encoder_config:
      sample_key: video
      prediction_key: video_embeddings
      img_size: 224 # 288 in the original coca
      n_classes: Null # Disable vision transformer head
      n_layer: 6
      attention_config:
        attention_engine_type: default_attention
      n_head: 8
      n_embd: 768
      dropout: 0.0
      patch_size: 16 # 18 in the original coca
      patch_stride: 16 # 18 in the original coca
      n_img_channels: 3
      add_cls_token: False
      bias: True
      num_video_frames: 16
      n_latents: 64
    text_decoder_config:
      sample_key: input_ids
      prediction_key: logits
      block_size: 1024
      vocab_size: 50304
      n_layer_text: 6
      n_layer_multimodal_text: 6
      attention_config:
        attention_engine_type: default_attention
      n_head: 12
      ffn_hidden: 2048
      n_embd: 768
      dropout: 0.0
      bias: true
      activation: swiglu
      epsilon: 1e-5
    n_pool_head: 12
    n_queries: 256
    bias_attn_pool: False
    epsilon_attn_pool: 1e-5
