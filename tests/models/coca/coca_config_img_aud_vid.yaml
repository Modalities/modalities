prediction_key: logits
audio_embd_prediction_key: audio_embeddings
image_embd_prediction_key: image_embeddings
video_embd_prediction_key: video_embeddings
text_embd_prediction_key: text_embeddings
image_cls_prediction_key: image_cls
image_text_cls_prediction_key: image_text_cls
audio_cls_prediction_key: audio_cls
audio_text_cls_prediction_key: audio_text_cls
video_cls_prediction_key: video_cls
video_text_cls_prediction_key: video_text_cls
text_cls_prediction_key: text_cls
modality_keys:
  - images
  - audio
  - audio_len
  - video
  - input_ids
is_audio_video: false
individual_datasets: true
logit_scale_prediction_key: logit_scale
audio_encoder_config:
  sample_key: audio
  prediction_key: audio_embeddings
  block_size: 500
  n_mels: 128
  n_embd: 768
  n_heads: 4
  n_conformer_blocks: 3
  attention_config:
    attention_engine_type: default_attention
  pointwise_conv_kernel_size: 1
  depthwise_conv_kernel_size: 31
image_encoder_config:
  sample_key: images
  prediction_key: image_embeddings
  img_size: 224
  n_classes: Null # Disable vision transformer head
  n_layer: 6
  attention_config:
    attention_engine_type: pytorch_flash_attention
  n_head: 8
  n_embd: 768
  dropout: 0.0
  patch_size: 16
  patch_stride: 16
  n_img_channels: 3
  add_cls_token: False
  bias: True
video_encoder_config:
  sample_key: video
  prediction_key: video_embeddings
  img_size: 224
  n_classes: Null
  n_layer: 6
  attention_config:
    attention_engine_type: pytorch_flash_attention
  n_head: 8
  n_embd: 768
  dropout: 0.0
  patch_size: 16
  patch_stride: 16
  n_img_channels: 3
  add_cls_token: False
  bias: True
  num_video_frames: 16
  n_latents: 64
text_decoder_config:
  sample_key: input_ids
  prediction_key: text_embeddings
  block_size: 1024
  vocab_size: 50304
  n_layer_text: 6
  n_layer_multimodal_text: 6
  attention_config:
    attention_engine_type: pytorch_flash_attention
  n_head: 12
  ffn_hidden: 2048
  n_embd: 768
  dropout: 0.0
  bias: true
  activation: swiglu
  epsilon: 1e-5
n_pool_head: 12
n_queries: 256
bias_attn_pool: False
epsilon_attn_pool: 1e-5
