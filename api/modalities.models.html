

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>modalities.models package &mdash; Modalities 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="modalities.models.coca package" href="modalities.models.coca.html" />
    <link rel="prev" title="modalities.logging_broker.subscriber_impl package" href="modalities.logging_broker.subscriber_impl.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Modalities
              <img src="../_static/logo.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_cards.html">Model Cards</a></li>
<li class="toctree-l1"><a class="reference internal" href="../benchmarking.html">Benchmarking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues.html">Known Issues</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../memmap.html">MemMap Datasets</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Entrypoints</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../entrypoints.html">Entrypoints</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">VSCode Setup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../vs_code_setup.html">VSCode Setup</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Future Work</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../future_work.html">Future Work</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">modalities</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="modalities.html">modalities package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="modalities.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="modalities.checkpointing.html">modalities.checkpointing package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.config.html">modalities.config package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.conversion.html">modalities.conversion package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.dataloader.html">modalities.dataloader package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.inference.html">modalities.inference package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.logging_broker.html">modalities.logging_broker package</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">modalities.models package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.nn.html">modalities.nn package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.optimizers.html">modalities.optimizers package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.preprocessing.html">modalities.preprocessing package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.registry.html">modalities.registry package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.running_env.html">modalities.running_env package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.tokenization.html">modalities.tokenization package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.training.html">modalities.training package</a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.utils.html">modalities.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.api">modalities.api module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.batch">modalities.batch module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.evaluator">modalities.evaluator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.exceptions">modalities.exceptions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.gym">modalities.gym module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.loss_functions">modalities.loss_functions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.main">modalities.main module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.trainer">modalities.trainer module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities.util">modalities.util module</a></li>
<li class="toctree-l3"><a class="reference internal" href="modalities.html#module-modalities">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Modalities</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">modalities</a></li>
          <li class="breadcrumb-item"><a href="modalities.html">modalities package</a></li>
      <li class="breadcrumb-item active">modalities.models package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/api/modalities.models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="modalities-models-package">
<h1>modalities.models package<a class="headerlink" href="#modalities-models-package" title="Link to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Link to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.coca.html">modalities.models.coca package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca.attention_pooling">modalities.models.coca.attention_pooling module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.attention_pooling.AttentionPooling"><code class="docutils literal notranslate"><span class="pre">AttentionPooling</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.attention_pooling.AttentionPooling.forward"><code class="docutils literal notranslate"><span class="pre">AttentionPooling.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca.coca_model">modalities.models.coca.coca_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCa"><code class="docutils literal notranslate"><span class="pre">CoCa</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCa.forward"><code class="docutils literal notranslate"><span class="pre">CoCa.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig"><code class="docutils literal notranslate"><span class="pre">CoCaConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.bias_attn_pool"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.bias_attn_pool</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.epsilon_attn_pool"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.epsilon_attn_pool</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.model_config"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.n_pool_head"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.n_pool_head</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.n_vision_queries"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.n_vision_queries</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.prediction_key"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.text_cls_prediction_key"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.text_cls_prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.text_decoder_config"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.text_decoder_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.text_embd_prediction_key"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.text_embd_prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.vision_cls_prediction_key"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.vision_cls_prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.vision_embd_prediction_key"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.vision_embd_prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.CoCaConfig.vision_encoder_config"><code class="docutils literal notranslate"><span class="pre">CoCaConfig.vision_encoder_config</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.activation"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.activation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.attention_config"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.attention_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.bias"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.bias</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.block_size"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.block_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.dropout"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.epsilon"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.epsilon</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.ffn_hidden"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.ffn_hidden</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.model_config"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.n_embd"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.n_embd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.n_head"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.n_head</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.n_layer_multimodal_text"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.n_layer_multimodal_text</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.n_layer_text"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.n_layer_text</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.prediction_key"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.sample_key"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.sample_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.coca_model.TextDecoderConfig.vocab_size"><code class="docutils literal notranslate"><span class="pre">TextDecoderConfig.vocab_size</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca.collator">modalities.models.coca.collator module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig.model_config"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig.sample_keys"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig.sample_keys</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig.target_keys"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig.target_keys</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig.text_sample_key"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig.text_sample_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollateFnConfig.text_target_key"><code class="docutils literal notranslate"><span class="pre">CoCaCollateFnConfig.text_target_key</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.collator.CoCaCollatorFn"><code class="docutils literal notranslate"><span class="pre">CoCaCollatorFn</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca.multi_modal_decoder">modalities.models.coca.multi_modal_decoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.multi_modal_decoder.MultiModalTextDecoder"><code class="docutils literal notranslate"><span class="pre">MultiModalTextDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.multi_modal_decoder.MultiModalTextDecoder.forward"><code class="docutils literal notranslate"><span class="pre">MultiModalTextDecoder.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.multi_modal_decoder.TransformerBlock"><code class="docutils literal notranslate"><span class="pre">TransformerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.multi_modal_decoder.TransformerBlock.forward"><code class="docutils literal notranslate"><span class="pre">TransformerBlock.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca.text_decoder">modalities.models.coca.text_decoder module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.text_decoder.TextDecoder"><code class="docutils literal notranslate"><span class="pre">TextDecoder</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.coca.html#modalities.models.coca.text_decoder.TextDecoder.forward"><code class="docutils literal notranslate"><span class="pre">TextDecoder.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.coca.html#module-modalities.models.coca">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.components.html">modalities.models.components package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.components.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.components.html#module-modalities.models.components.layer_norms">modalities.models.components.layer_norms module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig.bias"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig.bias</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig.elementwise_affine"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig.elementwise_affine</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig.eps"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig.eps</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig.model_config"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.LayerNormConfig.normalized_shape"><code class="docutils literal notranslate"><span class="pre">LayerNormConfig.normalized_shape</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNorm"><code class="docutils literal notranslate"><span class="pre">RMSLayerNorm</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNorm.forward"><code class="docutils literal notranslate"><span class="pre">RMSLayerNorm.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNorm.reset_parameters"><code class="docutils literal notranslate"><span class="pre">RMSLayerNorm.reset_parameters()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNormConfig"><code class="docutils literal notranslate"><span class="pre">RMSLayerNormConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNormConfig.bias"><code class="docutils literal notranslate"><span class="pre">RMSLayerNormConfig.bias</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNormConfig.epsilon"><code class="docutils literal notranslate"><span class="pre">RMSLayerNormConfig.epsilon</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNormConfig.model_config"><code class="docutils literal notranslate"><span class="pre">RMSLayerNormConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.components.html#modalities.models.components.layer_norms.RMSLayerNormConfig.ndim"><code class="docutils literal notranslate"><span class="pre">RMSLayerNormConfig.ndim</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.components.html#module-modalities.models.components">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.gpt2.html">modalities.models.gpt2 package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.gpt2.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.gpt2.html#module-modalities.models.gpt2.collator">modalities.models.gpt2.collator module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.collator.GPT2LLMCollateFn"><code class="docutils literal notranslate"><span class="pre">GPT2LLMCollateFn</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.gpt2.html#module-modalities.models.gpt2.gpt2_model">modalities.models.gpt2.gpt2_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionConfig"><code class="docutils literal notranslate"><span class="pre">AttentionConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionConfig.QueryKeyValueTransformConfig"><code class="docutils literal notranslate"><span class="pre">AttentionConfig.QueryKeyValueTransformConfig</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionConfig.model_config"><code class="docutils literal notranslate"><span class="pre">AttentionConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionConfig.qkv_transforms"><code class="docutils literal notranslate"><span class="pre">AttentionConfig.qkv_transforms</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionImplementation"><code class="docutils literal notranslate"><span class="pre">AttentionImplementation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionImplementation.DAO_FLASH"><code class="docutils literal notranslate"><span class="pre">AttentionImplementation.DAO_FLASH</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionImplementation.MANUAL"><code class="docutils literal notranslate"><span class="pre">AttentionImplementation.MANUAL</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionImplementation.PYTORCH_FLASH"><code class="docutils literal notranslate"><span class="pre">AttentionImplementation.PYTORCH_FLASH</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention.execute_attention"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.execute_attention()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention.execute_qkv_transforms"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.execute_qkv_transforms()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention.forward"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention.projection"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.projection()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.CausalSelfAttention.repeat_kv_heads"><code class="docutils literal notranslate"><span class="pre">CausalSelfAttention.repeat_kv_heads()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2Block"><code class="docutils literal notranslate"><span class="pre">GPT2Block</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2Block.forward"><code class="docutils literal notranslate"><span class="pre">GPT2Block.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLM"><code class="docutils literal notranslate"><span class="pre">GPT2LLM</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLM.forward"><code class="docutils literal notranslate"><span class="pre">GPT2LLM.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLM.forward_impl"><code class="docutils literal notranslate"><span class="pre">GPT2LLM.forward_impl()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.activation_type"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.activation_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.attention_config"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.attention_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.attention_implementation"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.attention_implementation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.attention_norm_config"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.attention_norm_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.bias"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.bias</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.check_divisibility"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.check_divisibility()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.dropout"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.ffn_hidden"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.ffn_hidden</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.ffn_norm_config"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.ffn_norm_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.lm_head_norm_config"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.lm_head_norm_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.model_config"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.n_embd"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.n_embd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.n_head_kv"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.n_head_kv</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.n_head_q"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.n_head_q</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.n_layer"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.n_layer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.poe_type"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.poe_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.prediction_key"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.sample_key"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.sample_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.sequence_length"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.sequence_length</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.use_meta_device"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.use_meta_device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.use_weight_tying"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.use_weight_tying</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.validate_sizes"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.validate_sizes()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLMConfig.vocab_size"><code class="docutils literal notranslate"><span class="pre">GPT2LLMConfig.vocab_size</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.IdentityTransform"><code class="docutils literal notranslate"><span class="pre">IdentityTransform</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.IdentityTransform.forward"><code class="docutils literal notranslate"><span class="pre">IdentityTransform.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig"><code class="docutils literal notranslate"><span class="pre">LayerNormWrapperConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig.config"><code class="docutils literal notranslate"><span class="pre">LayerNormWrapperConfig.config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig.model_config"><code class="docutils literal notranslate"><span class="pre">LayerNormWrapperConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig.norm_type"><code class="docutils literal notranslate"><span class="pre">LayerNormWrapperConfig.norm_type</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNorms"><code class="docutils literal notranslate"><span class="pre">LayerNorms</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNorms.layer_norm"><code class="docutils literal notranslate"><span class="pre">LayerNorms.layer_norm</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNorms.rms_norm"><code class="docutils literal notranslate"><span class="pre">LayerNorms.rms_norm</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.PositionTypes"><code class="docutils literal notranslate"><span class="pre">PositionTypes</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.PositionTypes.ABSOLUTE"><code class="docutils literal notranslate"><span class="pre">PositionTypes.ABSOLUTE</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.PositionTypes.NOPE"><code class="docutils literal notranslate"><span class="pre">PositionTypes.NOPE</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.QueryKeyValueTransform"><code class="docutils literal notranslate"><span class="pre">QueryKeyValueTransform</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.QueryKeyValueTransform.forward"><code class="docutils literal notranslate"><span class="pre">QueryKeyValueTransform.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.QueryKeyValueTransformType"><code class="docutils literal notranslate"><span class="pre">QueryKeyValueTransformType</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.QueryKeyValueTransformType.IdentityTransform"><code class="docutils literal notranslate"><span class="pre">QueryKeyValueTransformType.IdentityTransform</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.QueryKeyValueTransformType.RotaryTransform"><code class="docutils literal notranslate"><span class="pre">QueryKeyValueTransformType.RotaryTransform</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.RotaryTransform"><code class="docutils literal notranslate"><span class="pre">RotaryTransform</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.RotaryTransform.apply_rotary_pos_emb"><code class="docutils literal notranslate"><span class="pre">RotaryTransform.apply_rotary_pos_emb()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.RotaryTransform.forward"><code class="docutils literal notranslate"><span class="pre">RotaryTransform.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.RotaryTransform.rotate_half"><code class="docutils literal notranslate"><span class="pre">RotaryTransform.rotate_half()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.TransformerMLP"><code class="docutils literal notranslate"><span class="pre">TransformerMLP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.TransformerMLP.forward"><code class="docutils literal notranslate"><span class="pre">TransformerMLP.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.manual_scaled_dot_product_attention"><code class="docutils literal notranslate"><span class="pre">manual_scaled_dot_product_attention()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.gpt2.html#module-modalities.models.gpt2">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.huggingface.html">modalities.models.huggingface package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface.html#module-modalities.models.huggingface.huggingface_model">modalities.models.huggingface.huggingface_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFaceModelTypes"><code class="docutils literal notranslate"><span class="pre">HuggingFaceModelTypes</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFaceModelTypes.AutoModelForCausalLM"><code class="docutils literal notranslate"><span class="pre">HuggingFaceModelTypes.AutoModelForCausalLM</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFaceModelTypes.AutoModelForMaskedLM"><code class="docutils literal notranslate"><span class="pre">HuggingFaceModelTypes.AutoModelForMaskedLM</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel.forward"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModel.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModel.fsdp_block_names"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModel.fsdp_block_names</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.huggingface_prediction_subscription_key"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.huggingface_prediction_subscription_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.kwargs"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.kwargs</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.model_args"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.model_args</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.model_config"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.model_name"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.model_name</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.model_type"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.model_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.prediction_key"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface.html#modalities.models.huggingface.huggingface_model.HuggingFacePretrainedModelConfig.sample_key"><code class="docutils literal notranslate"><span class="pre">HuggingFacePretrainedModelConfig.sample_key</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface.html#module-modalities.models.huggingface">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.huggingface_adapters.html">modalities.models.huggingface_adapters package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface_adapters.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface_adapters.html#module-modalities.models.huggingface_adapters.hf_adapter">modalities.models.huggingface_adapters.hf_adapter module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapter"><code class="docutils literal notranslate"><span class="pre">HFModelAdapter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapter.config_class"><code class="docutils literal notranslate"><span class="pre">HFModelAdapter.config_class</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapter.forward"><code class="docutils literal notranslate"><span class="pre">HFModelAdapter.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapter.prepare_inputs_for_generation"><code class="docutils literal notranslate"><span class="pre">HFModelAdapter.prepare_inputs_for_generation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapterConfig"><code class="docutils literal notranslate"><span class="pre">HFModelAdapterConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapterConfig.model_type"><code class="docutils literal notranslate"><span class="pre">HFModelAdapterConfig.model_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.HFModelAdapterConfig.to_json_string"><code class="docutils literal notranslate"><span class="pre">HFModelAdapterConfig.to_json_string()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.ModalitiesModelOutput"><code class="docutils literal notranslate"><span class="pre">ModalitiesModelOutput</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.ModalitiesModelOutput.attentions"><code class="docutils literal notranslate"><span class="pre">ModalitiesModelOutput.attentions</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.ModalitiesModelOutput.hidden_states"><code class="docutils literal notranslate"><span class="pre">ModalitiesModelOutput.hidden_states</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.huggingface_adapters.html#modalities.models.huggingface_adapters.hf_adapter.ModalitiesModelOutput.logits"><code class="docutils literal notranslate"><span class="pre">ModalitiesModelOutput.logits</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.huggingface_adapters.html#module-modalities.models.huggingface_adapters">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modalities.models.vision_transformer.html">modalities.models.vision_transformer package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.vision_transformer.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.vision_transformer.html#module-modalities.models.vision_transformer.vision_transformer_model">modalities.models.vision_transformer.vision_transformer_model module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.ImagePatchEmbedding"><code class="docutils literal notranslate"><span class="pre">ImagePatchEmbedding</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.ImagePatchEmbedding.forward"><code class="docutils literal notranslate"><span class="pre">ImagePatchEmbedding.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformer"><code class="docutils literal notranslate"><span class="pre">VisionTransformer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformer.forward"><code class="docutils literal notranslate"><span class="pre">VisionTransformer.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformer.forward_images"><code class="docutils literal notranslate"><span class="pre">VisionTransformer.forward_images()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerBlock"><code class="docutils literal notranslate"><span class="pre">VisionTransformerBlock</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerBlock.forward"><code class="docutils literal notranslate"><span class="pre">VisionTransformerBlock.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.add_cls_token"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.add_cls_token</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.attention_config"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.attention_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.bias"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.bias</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.dropout"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.dropout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.img_size"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.img_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.model_config"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.model_config</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.n_classes"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.n_classes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.n_embd"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.n_embd</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.n_head"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.n_head</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.n_img_channels"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.n_img_channels</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.n_layer"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.n_layer</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.patch_size"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.patch_size</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.patch_stride"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.patch_stride</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.prediction_key"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.prediction_key</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="modalities.models.vision_transformer.html#modalities.models.vision_transformer.vision_transformer_model.VisionTransformerConfig.sample_key"><code class="docutils literal notranslate"><span class="pre">VisionTransformerConfig.sample_key</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modalities.models.vision_transformer.html#module-modalities.models.vision_transformer">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-modalities.models.model">
<span id="modalities-models-model-module"></span><h2>modalities.models.model module<a class="headerlink" href="#module-modalities.models.model" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.model.ActivationType">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.model.</span></span><span class="sig-name descname"><span class="pre">ActivationType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#ActivationType"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.ActivationType" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/enum.html#enum.Enum" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></a></p>
<p>Enum class representing different activation types.</p>
<dl class="simple">
<dt>Attributes:</dt><dd><p>GELU (str): GELU activation type.
SWIGLU (str): SWIGLU activation type.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="modalities.models.model.ActivationType.GELU">
<span class="sig-name descname"><span class="pre">GELU</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'gelu'</span></em><a class="headerlink" href="#modalities.models.model.ActivationType.GELU" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="modalities.models.model.ActivationType.SWIGLU">
<span class="sig-name descname"><span class="pre">SWIGLU</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'swiglu'</span></em><a class="headerlink" href="#modalities.models.model.ActivationType.SWIGLU" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.model.NNModel">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.model.</span></span><span class="sig-name descname"><span class="pre">NNModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_decay_groups</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#NNModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.NNModel" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>NNModel class to define a base model.</p>
<p>Initializes an NNModel object.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>seed (int, optional): The seed value for random number generation. Defaults to None.
weight_decay_groups (Optional[WeightDecayGroups], optional): The weight decay groups. Defaults to None.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>weight_decay_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em><em>] </em><em>| </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model.NNModel.forward">
<em class="property"><span class="k"><span class="pre">abstractmethod</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#NNModel.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.NNModel.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>inputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>Tensor</em></a><em>]</em>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>inputs (dict[str, torch.Tensor]): A dictionary containing input tensors.</p>
</dd>
<dt>Returns:</dt><dd><p>dict[str, torch.Tensor]: A dictionary containing output tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model.NNModel.get_parameters">
<span class="sig-name descname"><span class="pre">get_parameters</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#NNModel.get_parameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.NNModel.get_parameters" title="Link to this definition"></a></dt>
<dd><p>Returns a dictionary of the model’s parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code></a>, <a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</span></p>
</dd>
</dl>
<dl class="simple">
<dt>Returns:</dt><dd><p>A dictionary where the keys are the parameter names and the values are the corresponding parameter tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="modalities.models.model.NNModel.weight_decay_groups">
<em class="property"><span class="k"><span class="pre">property</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">weight_decay_groups</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><span class="pre">dict</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><span class="pre">list</span></a><span class="p"><span class="pre">[</span></span><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><span class="pre">str</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></em><a class="headerlink" href="#modalities.models.model.NNModel.weight_decay_groups" title="Link to this definition"></a></dt>
<dd><p>Returns the weight decay groups.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>WeightDecayGroups: The weight decay groups.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.model.SwiGLU">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.model.</span></span><span class="sig-name descname"><span class="pre">SwiGLU</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_embd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#SwiGLU"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.SwiGLU" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></p>
<p>SwiGLU class to define the SwiGLU activation function.</p>
<p>Initializes the SwiGLU object.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>n_embd (int): The number of embedding dimensions.
ffn_hidden (int): The number of hidden dimensions in the feed-forward network.
Best practice: 4 * n_embd (<a class="reference external" href="https://arxiv.org/pdf/1706.03762">https://arxiv.org/pdf/1706.03762</a>)
bias (bool): Whether to include bias terms in the linear layers.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_embd</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>ffn_hidden</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model.SwiGLU.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#SwiGLU.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.SwiGLU.forward" title="Link to this definition"></a></dt>
<dd><p>Forward pass of the SwiGLU module.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>x</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/tensors.html#torch.Tensor" title="(in PyTorch v2.8)"><em>Tensor</em></a>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>x (torch.Tensor): Input tensor.</p>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: Output tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modalities.models.model.model_predict_batch">
<span class="sig-prename descclassname"><span class="pre">modalities.models.model.</span></span><span class="sig-name descname"><span class="pre">model_predict_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model.html#model_predict_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model.model_predict_batch" title="Link to this definition"></a></dt>
<dd><p>Predicts the output for a batch of samples using the given model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="modalities.html#modalities.batch.InferenceResultBatch" title="modalities.batch.InferenceResultBatch"><code class="xref py py-class docutils literal notranslate"><span class="pre">InferenceResultBatch</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>batch</strong> (<a class="reference internal" href="modalities.html#modalities.batch.DatasetBatch" title="modalities.batch.DatasetBatch"><em>DatasetBatch</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The model used for prediction.
batch (DatasetBatch): The batch of samples to be predicted.</p>
</dd>
<dt>Returns:</dt><dd><p>InferenceResultBatch: The batch of inference results containing the predicted targets and predictions.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-modalities.models.model_factory">
<span id="modalities-models-model-factory-module"></span><h2>modalities.models.model_factory module<a class="headerlink" href="#module-modalities.models.model_factory" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.model_factory.GPT2ModelFactory">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.model_factory.</span></span><span class="sig-name descname"><span class="pre">GPT2ModelFactory</span></span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#GPT2ModelFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.GPT2ModelFactory" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.GPT2ModelFactory.get_gpt2_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_gpt2_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">poe_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sequence_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">vocab_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head_q</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_head_kv</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_embd</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_hidden</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_implementation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attention_norm_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ffn_norm_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lm_head_norm_config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_weight_tying</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_meta_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#GPT2ModelFactory.get_gpt2_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.GPT2ModelFactory.get_gpt2_model" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLM" title="modalities.models.gpt2.gpt2_model.GPT2LLM"><code class="xref py py-class docutils literal notranslate"><span class="pre">GPT2LLM</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>sample_key</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>prediction_key</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>poe_type</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.PositionTypes" title="modalities.models.gpt2.gpt2_model.PositionTypes"><em>PositionTypes</em></a>)</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>vocab_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>n_layer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>n_head_q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>n_head_kv</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>n_embd</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>ffn_hidden</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
<li><p><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.13)"><em>float</em></a>)</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
<li><p><strong>activation_type</strong> (<a class="reference internal" href="#modalities.models.model.ActivationType" title="modalities.models.model.ActivationType"><em>ActivationType</em></a>)</p></li>
<li><p><strong>attention_implementation</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionImplementation" title="modalities.models.gpt2.gpt2_model.AttentionImplementation"><em>AttentionImplementation</em></a>)</p></li>
<li><p><strong>attention_config</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.AttentionConfig" title="modalities.models.gpt2.gpt2_model.AttentionConfig"><em>AttentionConfig</em></a>)</p></li>
<li><p><strong>attention_norm_config</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig" title="modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig"><em>LayerNormWrapperConfig</em></a>)</p></li>
<li><p><strong>ffn_norm_config</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig" title="modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig"><em>LayerNormWrapperConfig</em></a>)</p></li>
<li><p><strong>lm_head_norm_config</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig" title="modalities.models.gpt2.gpt2_model.LayerNormWrapperConfig"><em>LayerNormWrapperConfig</em></a>)</p></li>
<li><p><strong>use_weight_tying</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
<li><p><strong>use_meta_device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> | </em><em>None</em>)</p></li>
<li><p><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.GPT2ModelFactory.get_gpt2_tensor_parallelized_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_gpt2_tensor_parallelized_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_mesh</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#GPT2ModelFactory.get_gpt2_tensor_parallelized_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.GPT2ModelFactory.get_gpt2_tensor_parallelized_model" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference internal" href="modalities.models.gpt2.html#modalities.models.gpt2.gpt2_model.GPT2LLM" title="modalities.models.gpt2.gpt2_model.GPT2LLM"><em>GPT2LLM</em></a>)</p></li>
<li><p><strong>device_mesh</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/distributed.html#torch.distributed.device_mesh.DeviceMesh" title="(in PyTorch v2.8)"><em>DeviceMesh</em></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.model_factory.</span></span><span class="sig-name descname"><span class="pre">ModelFactory</span></span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Model factory class to create models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_activation_checkpointed_fsdp1_model_">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_activation_checkpointed_fsdp1_model_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation_checkpointing_modules</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_activation_checkpointed_fsdp1_model_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_activation_checkpointed_fsdp1_model_" title="Link to this definition"></a></dt>
<dd><p>Apply activation checkpointing to the given FSDP1-wrapped model (in-place operation).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyShardedDataParallel</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel" title="(in PyTorch v2.8)"><em>FullyShardedDataParallel</em></a>)</p></li>
<li><p><strong>activation_checkpointing_modules</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>model (FSDP1): The FSDP1-wrapped model to apply activation checkpointing to.
activation_checkpointing_modules (list[str]): List of module names to apply activation checkpointing to.</p>
</dd>
<dt>Raises:</dt><dd><p>ValueError: Activation checkpointing can only be applied to FSDP1-wrapped models!</p>
</dd>
<dt>Returns:</dt><dd><p>FSDP1: The model with activation checkpointing applied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_activation_checkpointed_fsdp2_model_">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_activation_checkpointed_fsdp2_model_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ac_variant</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers_fqn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ac_fun_params</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_activation_checkpointed_fsdp2_model_"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_activation_checkpointed_fsdp2_model_" title="Link to this definition"></a></dt>
<dd><p>FSDP2 variant for applying activation checkpointing to the given model (in-place operation).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>ac_variant</strong> (<a class="reference internal" href="modalities.training.activation_checkpointing.html#modalities.training.activation_checkpointing.activation_checkpointing_variants.ActivationCheckpointingVariants" title="modalities.training.activation_checkpointing.activation_checkpointing_variants.ActivationCheckpointingVariants"><em>ActivationCheckpointingVariants</em></a>)</p></li>
<li><p><strong>layers_fqn</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a>)</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>ac_fun_params</strong> (<a class="reference internal" href="modalities.config.html#modalities.config.config.ActivationCheckpointedModelConfig.FullACParams" title="modalities.config.config.ActivationCheckpointedModelConfig.FullACParams"><em>FullACParams</em></a><em> | </em><a class="reference internal" href="modalities.config.html#modalities.config.config.ActivationCheckpointedModelConfig.SelectiveLayerACParams" title="modalities.config.config.ActivationCheckpointedModelConfig.SelectiveLayerACParams"><em>SelectiveLayerACParams</em></a><em> | </em><a class="reference internal" href="modalities.config.html#modalities.config.config.ActivationCheckpointedModelConfig.SelectiveOpACParams" title="modalities.config.config.ActivationCheckpointedModelConfig.SelectiveOpACParams"><em>SelectiveOpACParams</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Important: When using FSDP2, we always first apply activation checkpointing to the model</dt><dd><p>and then wrap it with FSDP2.</p>
</dd>
<dt>Args:</dt><dd><p>ac_variant (ActivationCheckpointingVariants): The activation checkpointing variant to use.
layers_fqn (str): Fully qualified name (FQN) of the layers to apply activation checkpointing to.
model (nn.Module): The (unwrapped) model to apply activation checkpointing to.
ac_fun_params (ACM.FullACParams  |  ACM.SelectiveLayerACParams  |  ACM.SelectiveOpACParams):</p>
<blockquote>
<div><p>The parameters for the activation checkpointing function, depending on the variant.</p>
</div></blockquote>
</dd>
<dt>Raises:</dt><dd><p>ValueError: Activation checkpointing can only be applied to unwrapped nn.Module models</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Module: The model with activation checkpointing applied.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_compiled_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_compiled_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fullgraph</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_compiled_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_compiled_model" title="Link to this definition"></a></dt>
<dd><p>Apply torch.compile to each transformer block, which makes compilation efficient due to
repeated structure. Alternatively one can compile the whole model (after applying DP).
Inspired by: <a class="reference external" href="https://github.com/pytorch/torchtitan/blob/6b2912a9b53464bfef744e62100716271b2b248f/torchtitan/parallelisms/parallelize_llama.py#L275">https://github.com/pytorch/torchtitan/blob/6b2912a9b53464bfef744e62100716271b2b248f/torchtitan/parallelisms/parallelize_llama.py#L275</a></p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>block_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>)</p></li>
<li><p><strong>fullgraph</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
<li><p><strong>debug</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a><em> | </em><em>None</em>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Note: With fullgraph=True, we enforce the block to be compiled as a whole, which raises an error on</dt><dd><p>graph breaks and maximizes speedup.</p>
</dd>
<dt>Args:</dt><dd><p>model (nn.Module): The model to be compiled.
block_names (list[str]): List of block names to be compiled individually.
fullgraph (bool): Flag enforcing the block to be compiled without graph breaks.
debug (Optional[bool]): Flag to enable debug mode. Default is False.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Module: The compiled model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_debugging_enriched_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_debugging_enriched_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_dir_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tracked_ranks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_interval_steps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_debugging_enriched_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_debugging_enriched_model" title="Link to this definition"></a></dt>
<dd><p>Enriches the model with debugging hooks to log tensor statistics during forward and backward passes.
During the forward pass, it logs the input and output tensors of each module, as well as the parameters.
Similarly, during the backward pass, it logs the gradients of the output tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>logging_dir_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><em>Path</em></a>)</p></li>
<li><p><strong>tracked_ranks</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Set" title="(in Python v3.13)"><em>Set</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a><em>] </em><em>| </em><em>None</em>)</p></li>
<li><p><strong>log_interval_steps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.13)"><em>int</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>The following tensor statistics are logged:</dt><dd><ul class="simple">
<li><p>global shape</p></li>
<li><p>local shape</p></li>
<li><p>is_dtensor (whether the tensor is a DTensor)</p></li>
<li><p>nan count</p></li>
<li><p>inf count</p></li>
<li><p>mean</p></li>
<li><p>std</p></li>
<li><p>min</p></li>
<li><p>max</p></li>
</ul>
</dd>
</dl>
<p>The statistics are written to a JSONL file in the specified logging directory.</p>
<dl>
<dt>Args:</dt><dd><p>model (nn.Module): The model to be enriched with debugging hooks.
logging_dir_path (Path): The directory path where the tensor statistics will be logged.
tracked_ranks (Optional[Set[int]]): A set of ranks to track. If provided, only these ranks</p>
<blockquote>
<div><p>will log the statistics. If None, all ranks will log the statistics.</p>
</div></blockquote>
<p>log_interval_steps (int): The interval in steps at which to log the tensor statistics. Default is 1.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_fsdp1_checkpointed_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_fsdp1_checkpointed_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint_loading</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">checkpoint_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_fsdp1_checkpointed_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_fsdp1_checkpointed_model" title="Link to this definition"></a></dt>
<dd><p>Loads a FSDP1 checkpointed model from the given checkpoint path.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyShardedDataParallel</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>checkpoint_loading</strong> (<a class="reference internal" href="modalities.checkpointing.html#modalities.checkpointing.checkpoint_loading.FSDP1CheckpointLoadingIF" title="modalities.checkpointing.checkpoint_loading.FSDP1CheckpointLoadingIF"><em>FSDP1CheckpointLoadingIF</em></a>)</p></li>
<li><p><strong>checkpoint_path</strong> (<a class="reference external" href="https://docs.python.org/3/library/pathlib.html#pathlib.Path" title="(in Python v3.13)"><em>Path</em></a>)</p></li>
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Args:</dt><dd><dl class="simple">
<dt>checkpoint_loading (FSDP1CheckpointLoadingIF): The checkpoint loading</dt><dd><p>approach used to load the model checkpoint.</p>
</dd>
</dl>
<p>checkpoint_path (Path): The path to the checkpoint file.
model (nn.Module): The model to be loaded with the checkpoint.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Module: The loaded wrapped model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_fsdp1_wrapped_model">
<span class="sig-name descname"><span class="pre">get_fsdp1_wrapped_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sync_module_states</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mixed_precision_settings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sharding_strategy</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_fsdp1_wrapped_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_fsdp1_wrapped_model" title="Link to this definition"></a></dt>
<dd><p>Get the FSDP1-wrapped model.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FullyShardedDataParallel</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>sync_module_states</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
<li><p><strong>block_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>)</p></li>
<li><p><strong>mixed_precision_settings</strong> (<a class="reference internal" href="modalities.running_env.html#modalities.running_env.env_utils.MixedPrecisionSettings" title="modalities.running_env.env_utils.MixedPrecisionSettings"><em>MixedPrecisionSettings</em></a>)</p></li>
<li><p><strong>sharding_strategy</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/fsdp.html#torch.distributed.fsdp.ShardingStrategy" title="(in PyTorch v2.8)"><em>ShardingStrategy</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The original model to be wrapped.
sync_module_states (bool): Whether to synchronize module states across ranks.
block_names (list[str]): List of block names.
mixed_precision_settings (MixedPrecisionSettings): Mixed precision settings.
sharding_strategy (ShardingStrategy): Sharding strategy.</p>
</dd>
<dt>Returns:</dt><dd><p>FSDP1: The FSDP1-wrapped model.</p>
</dd>
<dt>Note:</dt><dd><p>‘FSDPTransformerAutoWrapPolicyFactory` is hardcoded and should be passed in instead.
Different auto wrap policies may be supported in the future.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_fsdp2_wrapped_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_fsdp2_wrapped_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_names</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device_mesh</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mixed_precision_settings</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reshard_after_forward</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_fsdp2_wrapped_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_fsdp2_wrapped_model" title="Link to this definition"></a></dt>
<dd><p>Get the FSDP2-wrapped model.</p>
<p>Based on <a class="reference external" href="https://github.com/pytorch/torchtitan/blob/de9fd2b9ea7e763c9182e0df81fc32c2618cc0b6/torchtitan/parallelisms/parallelize_llama.py#L459">https://github.com/pytorch/torchtitan/blob/de9fd2b9ea7e763c9182e0df81fc32c2618cc0b6/torchtitan/parallelisms/parallelize_llama.py#L459</a>
and <a class="reference external" href="https://github.com/pytorch/torchtitan/blob/43584e0a4e72645e25cccd05d86f9632587a8beb/docs/fsdp.md">https://github.com/pytorch/torchtitan/blob/43584e0a4e72645e25cccd05d86f9632587a8beb/docs/fsdp.md</a>
NOTE: Torch Titan already implement pipeline parallelism. We skip that here for now.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/distributed.fsdp.fully_shard.html#torch.distributed.fsdp.FSDPModule" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">FSDPModule</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>block_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.13)"><em>list</em></a><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.13)"><em>str</em></a><em>]</em>)</p></li>
<li><p><strong>device_mesh</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/distributed.html#torch.distributed.device_mesh.DeviceMesh" title="(in PyTorch v2.8)"><em>DeviceMesh</em></a>)</p></li>
<li><p><strong>mixed_precision_settings</strong> (<a class="reference internal" href="modalities.running_env.html#modalities.running_env.env_utils.FSDP2MixedPrecisionSettings" title="modalities.running_env.env_utils.FSDP2MixedPrecisionSettings"><em>FSDP2MixedPrecisionSettings</em></a>)</p></li>
<li><p><strong>reshard_after_forward</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.13)"><em>bool</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The original model to be wrapped.
block_names (list[str]): List of block names.
device_mesh (DeviceMesh): The device mesh.
mixed_precision_settings (FSDP2MixedPrecisionSettings): Mixed precision settings.
reshard_after_forward (bool): Whether to reshard after forward.</p>
</dd>
<dt>Returns:</dt><dd><p>FSDP2: The FSDP2-wrapped model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="modalities.models.model_factory.ModelFactory.get_weight_initialized_model">
<em class="property"><span class="k"><span class="pre">static</span></span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_weight_initialized_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_initializer</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/model_factory.html#ModelFactory.get_weight_initialized_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.model_factory.ModelFactory.get_weight_initialized_model" title="Link to this definition"></a></dt>
<dd><p>Initializes the given model with weights using the provided model initializer.
The model can be on a meta device.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a></span></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>model</strong> (<a class="reference external" href="https://docs.pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch v2.8)"><em>Module</em></a>)</p></li>
<li><p><strong>model_initializer</strong> (<a class="reference internal" href="modalities.nn.model_initialization.html#modalities.nn.model_initialization.initialization_if.ModelInitializationIF" title="modalities.nn.model_initialization.initialization_if.ModelInitializationIF"><em>ModelInitializationIF</em></a>)</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Args:</dt><dd><p>model (nn.Module): The model to be initialized with weights.
model_initializer (ModelInitializationIF): The model initializer object.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Module: The initialized model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-modalities.models.utils">
<span id="modalities-models-utils-module"></span><h2>modalities.models.utils module<a class="headerlink" href="#module-modalities.models.utils" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="modalities.models.utils.ModelTypeEnum">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">modalities.models.utils.</span></span><span class="sig-name descname"><span class="pre">ModelTypeEnum</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/utils.html#ModelTypeEnum"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.utils.ModelTypeEnum" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/enum.html#enum.Enum" title="(in Python v3.13)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Enum</span></code></a></p>
<p>Enumeration class representing different types of models.</p>
<dl class="simple">
<dt>Attributes:</dt><dd><p>MODEL (str): Represents a regular model.
CHECKPOINTED_MODEL (str): Represents a checkpointed model.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="modalities.models.utils.ModelTypeEnum.CHECKPOINTED_MODEL">
<span class="sig-name descname"><span class="pre">CHECKPOINTED_MODEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'checkpointed_model'</span></em><a class="headerlink" href="#modalities.models.utils.ModelTypeEnum.CHECKPOINTED_MODEL" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="modalities.models.utils.ModelTypeEnum.MODEL">
<span class="sig-name descname"><span class="pre">MODEL</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'model'</span></em><a class="headerlink" href="#modalities.models.utils.ModelTypeEnum.MODEL" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="modalities.models.utils.get_model_from_config">
<span class="sig-prename descclassname"><span class="pre">modalities.models.utils.</span></span><span class="sig-name descname"><span class="pre">get_model_from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/modalities/models/utils.html#get_model_from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#modalities.models.utils.get_model_from_config" title="Link to this definition"></a></dt>
<dd><p>Retrieves a model from the given configuration based on the specified model type.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>config (dict): The configuration dictionary.
model_type (ModelTypeEnum): The type of the model to retrieve.</p>
</dd>
<dt>Returns:</dt><dd><p>Any: The model object based on the specified model type.</p>
</dd>
<dt>Raises:</dt><dd><p>NotImplementedError: If the model type is not supported.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.13)"><em>dict</em></a>)</p></li>
<li><p><strong>model_type</strong> (<a class="reference internal" href="#modalities.models.utils.ModelTypeEnum" title="modalities.models.utils.ModelTypeEnum"><em>ModelTypeEnum</em></a>)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-modalities.models">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-modalities.models" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modalities.logging_broker.subscriber_impl.html" class="btn btn-neutral float-left" title="modalities.logging_broker.subscriber_impl package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="modalities.models.coca.html" class="btn btn-neutral float-right" title="modalities.models.coca package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Fraunhofer.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>