from dataclasses import dataclass
import mmap
import pickle
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Optional
from modalities.exceptions import ReaderIndexationError
import numpy as np
from enum import Enum

@dataclass
class Sample:
    # If the index is not shuffled, then the incrementeal_line_id
    # points to the position in the dataset
    # If the index is shuffled, then the incremental_line_id 
    # points to the position in the shuffled index and the 
    # shuffled_line_id points to the position in the original index
    incremental_line_id: int
    raw_data_path: Path
    offset: int
    sample_length_in_bytes: int
    content_raw: str | bytes
    content_tokenized: Optional[bytes] = None
    shuffled_line_id: Optional[int] = None


class BaseReader(ABC):
    @abstractmethod
    def __len__(self) -> int:
        raise NotImplementedError

    @abstractmethod
    def __getitem__(self, key: int) -> Sample:
        raise NotImplementedError


class LocalLargeFileLinesReader(BaseReader):
    """LargeFileLinesReader class that read lines from a large file efficiently."""

    def __init__(
        self,
        raw_data_path: Path,
        index_path: Optional[Path] = None,
        encoding: Optional[str] = "utf-8",
        use_sample_length_from_index: bool = True,
    ):
        """
        Initializes a LargeFileLinesReader object.

        Args:
            raw_data_path (Path): Path to a jsonl file, which holds text data.
            index_path (Optional[Path]): Path to an index file, which indicates the start character/byte position
                         and length of samples given in `raw_data_path`.
                         If not defined, an index next to `raw_data_path` is picked,
                         by replacing its suffix with ".idx".
            encoding (Optional[str]): The encoding of the file (default: "utf-8").
                         If encoding is None, the raw data is read as bytes.
            use_sample_length_from_index (bool): If True, the sample length is taken from the index file
                        i.e., the (offset, sample_length) pairs. If False, the sample length is calculated
                        as the difference between the starting point of the next and the current sample.
        Returns:
            None
        """
        self.encoding = encoding
        self.raw_data_path = raw_data_path
        self.index_path = self.default_index_path(self.raw_data_path, index_path)
        self.use_sample_length_from_index = use_sample_length_from_index

        if not self.raw_data_path.is_file():
            raise FileNotFoundError("Raw data file does not exist")
        if not self.index_path.is_file():
            raise FileNotFoundError("Index file does not exist. Use `modalities data create_raw_index` to create one.")

        with self.index_path.open("rb") as f:
            self.index = pickle.load(f)

        self.raw_data_fd = self.raw_data_path.open("rb")
        self.mmapped_data_file = mmap.mmap(self.raw_data_fd.fileno(), 0, access=mmap.ACCESS_READ)

    def close(self):
        self.mmapped_data_file.close()
        self.raw_data_fd.close()

    @staticmethod
    def default_index_path(raw_data_path: Path, index_path: Optional[Path] = None) -> Path:
        """
        Returns the default index path for the given raw data path.

        Args:
            raw_data_path (Path): The path to the raw data file.
            index_path (Optional[Path]): The path to the index file (default: None).

        Returns:
            Path: The default index path.

        Note:
            If `index_path` is not provided, the default index path is generated by
              appending the extension ".idx" to the stem of the `raw_data_path`.
        """
        if index_path is None:
            default_index_path = Path(raw_data_path.parent, f"{raw_data_path.stem}.idx")
            print(f"No specific Index Path provided. Pointing to index next to input data at: {default_index_path}")
            return default_index_path
        return index_path

    def __len__(self) -> int:
        """
        Returns the length of the index.

        Returns:
            int: The length of the index.
        """
        return len(self.index)

    def __getitem__(self, key: int) -> Sample:
        """
        Retrieves an item from the LargeFileLinesReader.

        Args:
            key (int): The index used to retrieve the item.

        Returns:
            Sample: The item retrieved from the LargeFileLinesReader.

        Raises:
            IndexError: If the key is out of range.

        """

        offset, sample_length_in_bytes = self.index[key]

        # If use_sample_length_from_index = False, we calculate the sample length as the difference between the
        # starting point of the next and the current sample.
        # This allows for reading in the entire sample including the newline character.
        if not self.use_sample_length_from_index:
            if key + 1 < len(self.index):
                sample_length_in_bytes = self.index[key + 1][0] - self.index[key][0]
            else:
                sample_length_in_bytes = len(self.mmapped_data_file) - offset

        content = self._read_from_raw_file(offset, sample_length_in_bytes)
        return Sample(
            raw_data_path=self.raw_data_path,
            incremental_line_id=key,
            shuffled_line_id=key,   # TODO so far we don't support shuffling here!
            offset=offset,
            sample_length_in_bytes=sample_length_in_bytes,
            content_raw=content,
        )

    def _read_from_raw_file(self, offset: int, sample_length_in_bytes: int) -> str | bytes:
        # Reads a specified number of bytes from a raw file starting from a given offset.
        data = self.mmapped_data_file[offset : offset + sample_length_in_bytes]
        if self.encoding is not None:
            data_decoded = data.decode(self.encoding)
            return data_decoded
        return data


class GlobalLargeFileLinesReader(BaseReader):
    """LargeFileLinesReader class that read lines from a large file efficiently."""

    def __init__(
        self,
        global_inorder_index_path: Path,
        raw_data_file_list_path: Path,
        raw_data_root_path: Path,
        global_shuffle_index_path: Optional[Path] = None,
        encoding: Optional[str] = "utf-8",
    ):
        self.global_inorder_index_path = global_inorder_index_path
        self.raw_data_file_list_path = raw_data_file_list_path
        self.raw_data_root_path = raw_data_root_path
        self.global_shuffle_index_path = global_shuffle_index_path
        self.encoding = encoding

        # create the raw data file path list (the JSONL files)
        # the file paths are relative to the raw_data_root_path
        with open(self.raw_data_file_list_path, "r", encoding="utf-8") as f:
            self.relative_raw_data_file_paths = [line.strip() for line in f.readlines()]

        self.relative_to_absolute_raw_data_file_paths = {
            rel_file_path: raw_data_root_path / rel_file_path for rel_file_path in self.relative_raw_data_file_paths
        }

        # open memmap  / index files
        num_rows, _, _ = np.memmap(self.global_inorder_index_path, dtype="int64", mode="r")[0:3]

        self.global_index_inorder = np.memmap(
            self.global_inorder_index_path, dtype="int64", mode="r", shape=(num_rows, 3)
        )
        if self.global_shuffle_index_path is not None:
            self.global_shuffle_index = np.memmap(self.global_shuffle_index_path, dtype="int64", mode="r")
        else:
            self.global_shuffle_index = None
            # the 0th element in the global_index_inorder contains the meta data (num_rows, num_cols, is_shuffled)
            # therefore we have to skip the first element when iterating.
            # Note, when we iterate via the global_shuffle_index, we don't have to do this,
            # as the the shuffled index does not contain index 0.
            self.global_index_inorder = self.global_index_inorder[1:]

    def close(self):
        pass

    def __len__(self) -> int:
        """
        Returns the length of the index.

        Returns:
            int: The length of the index.
        """
        if self.global_shuffle_index is not None:
            return len(self.global_shuffle_index)
        else:
            return len(self.global_index_inorder)

    def __getitem__(self, key: int) -> Sample:
        """
        Retrieves an item from the LargeFileLinesReader.

        Args:
            key (int): The index used to retrieve the item.

        Returns:
            Sample: The item retrieved from the LargeFileLinesReader.

        Raises:
            IndexError: If the key is out of range.

        """
        try:
            if self.global_shuffle_index is not None: 
                mapped_key = self.global_shuffle_index[key]
            else:
                mapped_key = key
            file_index, offset, sample_length_in_bytes = self.global_index_inorder[mapped_key]
            rel_file_path = self.relative_raw_data_file_paths[file_index]
            abs_raw_file_path = self.relative_to_absolute_raw_data_file_paths[rel_file_path]
        except Exception as e:
            raise ReaderIndexationError(f"Error while reading sample with key {key}: {e}") from e

        with open(abs_raw_file_path, "rb") as fd:
            raw_data_mmap = mmap.mmap(fd.fileno(), 0, access=mmap.ACCESS_READ)
            content = raw_data_mmap[offset : offset + sample_length_in_bytes]
        if self.encoding is not None:
            content = content.decode(self.encoding)
        return Sample(
            incremental_line_id=key,
            shuffled_line_id=mapped_key,
            raw_data_path=abs_raw_file_path,
            offset=offset,
            sample_length_in_bytes=sample_length_in_bytes,
            content_raw=content,
        )


class LargeFileLinesReaderTypes(Enum):
    LOCAL = "LOCAL"
    GLOBAL = "GLOBAL"


class LargeFileLinesReaderFactory:

    @staticmethod
    def get_local_reader(
        raw_data_path: Path,
        index_path: Optional[Path] = None,
        encoding: Optional[str] = "utf-8",
    ) -> LocalLargeFileLinesReader:
        return LocalLargeFileLinesReader(
            raw_data_path=raw_data_path,
            index_path=index_path,
            encoding=encoding,
            use_sample_length_from_index=True,
        )

    @staticmethod
    def get_global_reader(
        global_inorder_index_path: Path,
        raw_data_file_list_path: Path,
        raw_data_root_path: Path,
        global_shuffle_index_path: Optional[Path] = None,
        encoding: Optional[str] = "utf-8",
    ) -> GlobalLargeFileLinesReader:
        return GlobalLargeFileLinesReader(
            global_inorder_index_path=global_inorder_index_path,
            raw_data_file_list_path=raw_data_file_list_path,
            raw_data_root_path=raw_data_root_path,
            global_shuffle_index_path=global_shuffle_index_path,
            encoding=encoding,
        )
