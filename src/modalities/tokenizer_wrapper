from typing import Optional
import sentencepiece.sentencepiece_model_pb2 as model
import sentencepiece as spm
from transformers import PreTrainedTokenizer

class TokenizerWrapper:
    def __call__(self, text: str, max_length: Optional[int]=None, padding: Optional[bool]=None, truncation: Optional[bool]=None):
        raise NotImplementedError("Tokenizer must be implemented by a subclass.")

class PreTrainedHFTokenizer(TokenizerWrapper):

    def __init__(self, tokenizer: PreTrainedTokenizer) -> None:
        self.tokenizer = tokenizer

    def __call__(self, text, max_length, padding, truncation):
        return self.tokenizer.__call__(text, max_length=max_length, padding=padding, truncation=truncation)

class PreTrainedSPTokenizer(TokenizerWrapper):
    
    def __init__(self, tokenizer: spm.SentencePieceProcessor = None):
        self.tokenizer = tokenizer
        self.tokenizer_config = None
        self.continuation_tokenizer = None
        self.add_prefix_space = None
        self.read_model_proto()

    def __call__(self, text: str, max_length: Optional[int]=None, padding: Optional[bool]= None, truncation: Optional[bool]=None):
            return self.tokenizer.encode(text)
